{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "driven-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def pdf_To_text(text):\n",
    "    # creating a pdf file object\n",
    "    pdf_file = open(text, 'rb')\n",
    "    # creating a pdf reader object\n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    # get number of pages in pdf file\n",
    "    number_of_pages = read_pdf.getNumPages()\n",
    "    #print the # of page\n",
    "    print(number_of_pages)\n",
    "    \n",
    "    #read page by page with getPage method\n",
    "    for i in range(0,number_of_pages):\n",
    "        p = read_pdf.getPage(i)\n",
    "        text += p.extractText()\n",
    "        \n",
    "    # text arrangement\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "informational-reputation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Deep_learning_for_NLP.pdf24 NatlSciRev ,2018,Vol.5,No.1 PERSPECTIVES ZongbenXu  andJianSun  Xi’anInternationalAcademyforMathematics& MathematicalTechnology,Xi’anJiaotong University,China  Correspondingauthors. E-mails: zbxu@mail.xjtu.edu.cn ; jiansun@mail.xjtu.edu.cn REFERENCES 1.LeCunY,BengioYandHintonG. Nature 2015; 521 :436–44. 2.GregorKandLeCunY. ICML 2010. 3.SchroffF,KalenichenkoDandPhilbinJ. CVPR 2015. 4.YonghuiW,SchusterMandZhifengChen etal. arXiv:1609.08144,2016. 5.SilverD,AjaHuangandChrisJ.Maddison etal. Nature 2016; 529 :484–9. 6.GulshanV,PengLandCoramM etal.Jama 2016; 316 :2402–10. 7.YangY,SunJandLiH etal.NIPS 2016. 8.SunJandTappenM. CVPR 2011. 9.SunJandTappenM. IEEETImageProcess 2013; 22 :402–8. 10.SunJ,SunJandXuZ. IEEETImageProcess 2015; 24 :4148–59. 11.SprechmannP,BronsteinAMandSapiroG. IEEE TPAMI 2015; 37 :1821–33. NationalScienceReview 5:22–24,2018 doi:10.1093/nsr/nwx099 Advanceaccesspublication25August2017 COMPUTERSCIENCE SpecialTopic:MachineLearning Deeplearningfornaturallanguageprocessing:advantages andchallenges HangLi INTRODUCTION Deeplearningreferstomachinelearning technologiesforlearningandutilizing ‘deep’aneuralnetworks,such asdeepneuralnetworks(DNN),con- volutionalneuralnetworks(CNN) andrecurrentneuralnetworks(RNN). Recently,deeplearninghasbeensuc- cessfullyappliedtonaturallanguage processingandprogress hasbeenmade.ispapersumma- rizestherecentadvancementofdeep learningfornaturallanguageprocess- inganddiscussesitsadvantagesand challenges. Wethinkthattherearemajor tasksinnaturallanguageprocessing,in- cludingmatching,transla- tion,structuredpredictionandthese- quentialdecisionprocess.Forthe fourtasks,itisfoundthatthedeeplearn- ingapproachhasoutperformedorsig- outperformedthetraditional approaches. End-to-endtrainingandrepresen- tationlearningarethekeyfeaturesof deeplearningthatmakeitapowerful toolfornaturallanguageprocess- ing.Deeplearningisnotalmighty, however.Itmightnotbesfor inferenceanddecisionmaking,which areessentialforcomplexproblemslike multi-turndialogue.Furthermore,how tocombinesymbolicprocessingandneu- ralprocessing,howtodealwiththelong tailphenomenon,etc.arealsochallenges ofdeeplearningfornaturallanguage processing. PROGRESSINNATURAL LANGUAGEPROCESSING Inourview,therearemajortasksin naturallanguageprocessing,namelyclas- matching,translation,struc- turedpredictionandthesequentialdeci- sionprocess.Mostoftheproblemsinnat- urallanguageprocessingcanbeformal- izedasthesetasks,assummarizedin Table 1 .Inthetasks,words,phrases,sen- tences,paragraphsandevendocuments areusuallyviewedasasequenceoftokens (strings)andtreatedsimilarly,although theyhavecomplexities.Infact, sentencesarethemostwidelyusedpro- cessingunits. Ithasbeenobservedrecently thatdeeplearningcanenhancethe performancesintherstfourtasksand becomesthestate-of-the-arttechnology forthetasks(e.g.[ 1 – 8 ]). Table 2 showstheperformancesof exampleproblemsinwhichdeeplearn- inghassurpassedtraditionalapproaches. AmongalltheNLPproblems,progress inmachinetranslationisparticularly remarkable.Neuralmachinetranslation, i.e.machinetranslationusingdeep learning,hasoutperformed traditionalstatisticalmachinetranslation. state-of-theartneuraltranslation systemsemploysequence-to-sequence learningmodelscomprisingRNNs [ 4 – 6 ]. Deeplearninghasalso,forthe time,madecertainapplicationspossi- ble.Forexample,deeplearninghasbeen successfullyappliedtoimageretrieval (alsoknownastexttoimage),inwhich queryandimagearetransformed intovectorrepresentationswithCNNs, therepresentationsarematchedwith DNNandtherelevanceoftheimageto thequeryiscalculated[ 3 ].Deeplearn- ingisalsoemployedingeneration-based naturallanguagedialogue,inwhich,given anthesystemautomatically generatesaresponseandthemodel Downloaded from https://academic.oup.com/nsr/article-abstract/5/1/24/4107792by gueston 04 April 2018PERSPECTIVES Li 25 Table1. Fivetasksinnaturallanguageprocessing. TaskDescriptionModelApplications assignalabeltoastring s  c s :string , c :label textsentimentanalysis Matchingmatchingtwostrings s , t  R + s :string , t :string R + :non − negativerealvalues search,questionanswering,singleturndialogue(retrieval based) Translationtransformonestringtoanother s  t s :string , t :string machinetranslation,automaticspeechrecognition,singleturn dialogue(generation-based) structuredpredictionmapastringtoastructure s  [ s ] s :string , [ s ]:structure namedentityrecognition,wordsegmentation,part-of-speech tagging,dependencyparsing,semanticparsing sequentialdecision process takeactionsinstatesindynamically changingenvironment  : s  a  :policy , s :state , a :action multi-turndialogue Table2. PerformancesofNaturalLanguageProcessingProblems. TaskExampleproblemDeeplearningTraditionalapproachReference sentimentCNN,acc = 86.8% SVM,acc = 79.4%[ 1 ] matchingsingleturndialogueCNN,p@1 = 49.6% MLP,p@1 = 36.1%[ 2 ] translationmachinetranslationNMT,BLEU = 39.0 SMT,BLEU = 37.0[ 6 ] structured prediction dependencyparsingacc = 91.8% acc = 90.7%[ 8 ] Table3. Advantagesandchallengesofdeeplearningfornaturallanguageprocessing. AdvantagesChallenges  goodatrecognitionproblems  data-driven,andperformanceishigh inmanyproblems  end-to-endtraining:lorno domainknowledgeisneededin systemconstruction  learnofrepresentations:cross-modal processingispossible  gradient-basedlearning:learning algorithmissimple  mainlysupervisedlearningmethods  notgoodatinferenceanddecisionmaking  cannotdirectlyhandlesymbols  data-hungryandthusisnotsuitablewhendata sizeissmall  tohandlelongtailphenomena  modelisusuallyablackboxandisdto understand  computationalcostoflearningishigh  unsupervisedlearningmethodsneedtobe developed  stilllacksoftheoreticalfoundation istrainedinsequence-to-sequence learning[ 7 ]. task,thesequentialdecision processsuchastheMarkovdecisionpro- cess,isthekeyissueinmulti-turndia- logue,asexplainedbelow.Ithasnotbeen thoroughlyvhowever,howdeep learningcancontributetothetask. ADVANTAGESAND CHALLENGES Deeplearningcertainlyhasadvantages andchallengeswhenappliedtonatural languageprocessing,assummarizedin Table 3 . Advantages Wethinkthat,amongtheadvantages, end-to-endtrainingandrepresentation learningreallydeeplearn- ingfromtraditionalmachinelearningap- proaches,andmakeitpowerfulmachin- eryfornaturallanguageprocessing. Itispossibletoperformend-to- endtrainingindeeplearningforanappli- cation.isbecausethemodel(deep neuralnetwork)orichrepresentabil- ityandinformationinthedatacanbeef- fectively‘encoded’inthemodel.Forex- ample,inneuralmachinetranslation,the modeliscompletelyautomaticallycon- structedfromaparallelcorpusandusu- allynohumaninterventionisneeded. isclearlyanadvantagecomparedto thetraditionalapproachofstatisticalma- chinetranslation,inwhichfeatureengi- neeringiscrucial. Withdeeplearning,therepresenta- tionsofdatainforms,suchas textandimage,canallbelearnedasreal- valuedvectors.ismakesitpossibleto performinformationprocessingacross multiplemodality.Forexample,inimage retrieval,itbecomesfeasibletomatchthe query(text)againstimagesandthe mostrelevantimages,becauseallofthem arerepresentedasvectors. Challenges arechallengesofdeeplearningthat aremorecommon,suchaslackofthe- oreticalfoundation,lackofinterpretabil- ityofmodel,andrequirementofalarge amountofdataandpowerfulcomputing resources.arealsochallengesthat aremoreuniquetonaturallanguagepro- cessing,namelydindealingwith longtail,incapabilityofdirectlyhandling symbols,andatinference anddecisionmaking. Datainnaturallanguagealwaysfol- lowapowerlawdistribution.Asare- sult,forexample,thesizeofthevocabu- laryincreasesasthesizeofthedatain- creases.meansthat,nohow Downloaded from https://academic.oup.com/nsr/article-abstract/5/1/24/4107792by gueston 04 April 201826 NatlSciRev ,2018,Vol.5,No.1 PERSPECTIVES muchdatatherearefortraining,thereal- waysexistcasesthatthetrainingdatacan- notcover.Howtodealwiththelongtail problemposesaschallengeto deeplearning.Byresortingtodeeplearn- ingalone,thisproblemwouldbehardto solve. Languagedataisbynaturesymbol data,whichisfromvectordata (real-valuedvectors)thatdeeplearning normallyutilizes.Currently,symboldata inlanguageareconvertedtovectordata andthenareinputintoneuralnetworks, andtheoutputfromneuralnetworksis furtherconvertedtosymboldata.Infact, alargeamountofknowledgefornatu- rallanguageprocessingisintheform ofsymbols,includinglinguisticknowl- edge(e.g.grammar),lexicalknowledge (e.g.WordNet)andworldknowledge (e.g.Wikipedia).Currently,deeplearn- ingmethodshavenotyetmadee tiveuseoftheknowledge.Symbolrepre- sentationsareeasytointerpretandma- nipulateand,ontheotherhand,vec- torrepresentationsarerobusttoambigu- ityandnoise.Howtocombinesymbol dataandvectordataandhowtoleverage thestrengthsofbothdatatypesremain anopenquestionfornaturallanguage processing. arecomplextasksinnaturallan- guageprocessing,whichmaynotbeeas- ilyrealizedwithdeeplearningalone.For example,multi-turndialogueamountsto averycomplicatedprocess.Itinvolves languageunderstanding,languagegener- ation,dialoguemanagement,knowledge baseaccessandinference.Dialogueman- agementcanbeformalizedasasequen- tialdecisionprocessandreinforcement learningcanplayacriticalrole.Obvi- ously,combinationofdeeplearningand reinforcementlearningcouldbepoten- tiallyusefulforthetask,whichisbeyond deeplearningitself. Insummary,therearestillanumber ofopenchallengeswithregardtodeep learningfornaturallanguageprocess- ing.Deeplearning,whencombined withothertechnologies(reinforce- mentlearning,inference,knowledge), mayfurtherpushthefrontierofthe  FUNDING workissupportedinpartbytheNationalBa- sicResearchProgramofChina(973Program, 2014CB340301). HangLi Noah’sArkLab,HuaweiTechnologies,HongKong, China E-mail: hangli65@hotmail.com REFERENCES 1.BlunsomP,GrefenstetteEandKalchbrennerN.A convolutionalneuralnetworkformodellingsen- tences.In: 52ndAnnualMeetingoftheAsso- ciationforComputationalLinguistics .Baltimore, USA,2014,655–65. 2.HuB,LuZandLiH.ConvolutionalNeuralNetwork ArchitecturesforMatchingNaturalLanguage Sentences.In: AdvancesinNeuralInformation ProcessingSystems27 .Montreal,Canada,2014, 2042–50. 3.MaL,LuZandShangL etal. MultimodalCon- volutionalNeuralNetworksforMatchingImage andSentence.In: IEEEInternationalConference onComputerVision .Santiago,Chile,2015,2623– 31. 4.ChoK,VanMerri ¨ enboerBandGulcehreC etal. Learningphraserepresentationsusingrnn encoder-decoderforstatisticalmachine.In: Con- ferenceonEmpiricalMethodsinNaturalLan- guageProcessing .Doha,Qatar,2014,1724–34. 5.BahdanauD,ChoKandBengioY.Neuralmachine translationbyjointlylearningtoalignandtrans- late.In: 3rdInternationalConferenceonLearning Representations .SanDiego,USA,2015. 6.WuY,SchusterMandChenZ.CoRR,vol. abs/1609.08144,2016. 7.ShangL,LuZandLiH.NeuralRespondingMa- chineforShort-TextConversation.In: 53thAn- nualMeetingofAssociationforComputational Linguisticsandthe7thInternationalJointCon- ferenceonNaturalLanguageProcessing .Beijing, China,2015,1577–86. 8.ChenDandManningCD.AFastandAccurate DependencyParserusingNeuralNetworks.In: ConferenceonEmpiricalMethodsinNaturalLan- guageProcessing .Doha,Qatar,2014,740–50. NationalScienceReview 5:24–26,2018 doi:10.1093/nsr/nwx110 Advanceaccesspublication8September2017 MULTIDISCIPLINARY SpecialTopic:MachineLearning Learningcausalityandcausality-relatedlearning:somerecent progress KunZhang 1,  ,BernhardSch ¨ olkopf 2 ,PeterSpirtes 1 andClarkGlymour 1 INTRODUCTION Causalityisafundamentalnotioninsci- ence,andplaysanimportantroleinex- planation,prediction,decisionmaking andcontrol.Recently,withtherapid accumulationofhugevolumesofdata,it isevenmoredesirabletoabstractcausal knowledgefromdata.Furthermore,such dataareusuallytimeseriesmeasured overarelativelylongtimeperiodorag- gregateddatafrommultipledatasets collectedinenvironmentsor underexperimentalconditions, leadingtotheissueofdataheterogene- ity.Causalityalsoprovidesawayto understandandtackledataheterogene- ity,whiletraditionalmachinelearning Downloaded from https://academic.oup.com/nsr/article-abstract/5/1/24/4107792by gueston 04 April 2018'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_To_text('Deep_learning_for_NLP.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-repository",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
